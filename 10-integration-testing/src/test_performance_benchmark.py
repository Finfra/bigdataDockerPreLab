#!/usr/bin/env python3
"""
FMS ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ (Kafka DNS ë¬¸ì œ íšŒí”¼)
Docker console consumerì™€ ê¸°ì¡´ data collectorë¥¼ í™œìš©í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import time
import subprocess
import json
from datetime import datetime
import logging

class FMSPerformanceBenchmark:
    def __init__(self):
        self.setup_logging()
        self.results = {}

    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger('FMS-Performance-Test')

    def test_kafka_cluster_health(self):
        """Kafka í´ëŸ¬ìŠ¤í„° ìƒíƒœ í…ŒìŠ¤íŠ¸"""
        self.logger.info("Testing Kafka cluster health...")
        
        try:
            # Kafka í† í”½ ë¦¬ìŠ¤íŠ¸ í™•ì¸
            result = subprocess.run([
                'docker', 'exec', 'fms-kafka-1', 
                'kafka-topics', '--bootstrap-server', 'kafka-1:9092', '--list'
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                topics = result.stdout.strip().split('\n')
                required_topics = ['fms-raw-data', 'fms-processed-data', 'fms-alerts', 'fms-quality-metrics']
                found_topics = [t for t in required_topics if t in topics]
                
                self.results['kafka_health'] = {
                    'status': 'PASS' if len(found_topics) == len(required_topics) else 'FAIL',
                    'topics_found': found_topics,
                    'topics_required': required_topics
                }
                
                self.logger.info(f"âœ… Kafka health check: {len(found_topics)}/{len(required_topics)} topics found")
                return True
            else:
                self.results['kafka_health'] = {
                    'status': 'FAIL',
                    'error': result.stderr
                }
                self.logger.error(f"âŒ Kafka health check failed: {result.stderr}")
                return False
                
        except Exception as e:
            self.results['kafka_health'] = {
                'status': 'FAIL',
                'error': str(e)
            }
            self.logger.error(f"âŒ Kafka health check failed: {str(e)}")
            return False

    def test_data_collector_performance(self):
        """FMS Data Collector ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        self.logger.info("Testing FMS Data Collector performance...")
        
        try:
            # í˜„ì¬ ë©”ì‹œì§€ ìˆ˜ í™•ì¸
            start_result = subprocess.run([
                'docker', 'exec', 'fms-kafka-1',
                'kafka-run-class', 'kafka.tools.GetOffsetShell',
                '--broker-list', 'kafka-1:9092',
                '--topic', 'fms-raw-data',
                '--time', '-1'
            ], capture_output=True, text=True, timeout=10)
            
            if start_result.returncode != 0:
                self.logger.warning("Could not get initial offset")
                start_offset = 0
            else:
                # íŒŒí‹°ì…˜ë³„ ì˜¤í”„ì…‹ íŒŒì‹±
                start_offset = sum([int(line.split(':')[-1]) for line in start_result.stdout.strip().split('\n') if line])
            
            # 30ì´ˆê°„ ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸°
            self.logger.info("Monitoring data collection for 30 seconds...")
            time.sleep(30)
            
            # ìµœì¢… ë©”ì‹œì§€ ìˆ˜ í™•ì¸
            end_result = subprocess.run([
                'docker', 'exec', 'fms-kafka-1',
                'kafka-run-class', 'kafka.tools.GetOffsetShell',
                '--broker-list', 'kafka-1:9092',
                '--topic', 'fms-raw-data',
                '--time', '-1'
            ], capture_output=True, text=True, timeout=10)
            
            if end_result.returncode != 0:
                self.logger.warning("Could not get final offset")
                end_offset = start_offset
            else:
                end_offset = sum([int(line.split(':')[-1]) for line in end_result.stdout.strip().split('\n') if line])
            
            messages_received = end_offset - start_offset
            throughput = messages_received / 30.0  # msg/sec
            
            self.results['data_collector_performance'] = {
                'status': 'PASS' if messages_received > 0 else 'FAIL',
                'monitoring_duration_sec': 30,
                'messages_received': messages_received,
                'throughput_msg_per_sec': round(throughput, 2),
                'start_offset': start_offset,
                'end_offset': end_offset
            }
            
            self.logger.info(f"âœ… Data collector performance:")
            self.logger.info(f"   - Messages received: {messages_received}")
            self.logger.info(f"   - Throughput: {throughput:.2f} msg/sec")
            
            return True
            
        except Exception as e:
            self.results['data_collector_performance'] = {
                'status': 'FAIL',
                'error': str(e)
            }
            self.logger.error(f"âŒ Data collector performance test failed: {str(e)}")
            return False

    def test_spark_cluster_health(self):
        """Spark í´ëŸ¬ìŠ¤í„° ìƒíƒœ í…ŒìŠ¤íŠ¸"""
        self.logger.info("Testing Spark cluster health...")
        
        try:
            # Spark Master ì›¹ UI ìƒíƒœ í™•ì¸
            import urllib.request
            
            response = urllib.request.urlopen('http://localhost:8080', timeout=10)
            content = response.read().decode('utf-8')
            
            if 'Spark Master' in content and 'Workers' in content:
                # Workers ê°œìˆ˜ í™•ì¸
                if 'Alive Workers:</strong> 1' in content:
                    workers_alive = 1
                else:
                    workers_alive = 0
                
                self.results['spark_health'] = {
                    'status': 'PASS' if workers_alive > 0 else 'WARN',
                    'workers_alive': workers_alive,
                    'master_status': 'ALIVE'
                }
                
                self.logger.info(f"âœ… Spark cluster health: Master ALIVE, {workers_alive} worker(s)")
                return True
            else:
                self.results['spark_health'] = {
                    'status': 'FAIL',
                    'error': 'Master UI not responding properly'
                }
                self.logger.error("âŒ Spark Master UI not responding properly")
                return False
                
        except Exception as e:
            self.results['spark_health'] = {
                'status': 'FAIL',
                'error': str(e)
            }
            self.logger.error(f"âŒ Spark health check failed: {str(e)}")
            return False

    def test_system_resources(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  í…ŒìŠ¤íŠ¸"""
        self.logger.info("Testing system resource usage...")
        
        try:
            # Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ ë° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  í™•ì¸
            stats_result = subprocess.run([
                'docker', 'stats', '--no-stream', '--format',
                'table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}'
            ], capture_output=True, text=True, timeout=10)
            
            if stats_result.returncode == 0:
                lines = stats_result.stdout.strip().split('\n')[1:]  # í—¤ë” ì œì™¸
                fms_containers = [line for line in lines if 'fms-' in line]
                
                total_containers = len(fms_containers)
                running_containers = len([line for line in fms_containers if line])
                
                self.results['system_resources'] = {
                    'status': 'PASS' if running_containers >= 5 else 'WARN',  # ìµœì†Œ 5ê°œ ì»¨í…Œì´ë„ˆ
                    'total_fms_containers': total_containers,
                    'running_containers': running_containers,
                    'container_stats': fms_containers[:5]  # ìƒìœ„ 5ê°œë§Œ
                }
                
                self.logger.info(f"âœ… System resources: {running_containers} FMS containers running")
                return True
            else:
                self.results['system_resources'] = {
                    'status': 'FAIL',
                    'error': stats_result.stderr
                }
                self.logger.error(f"âŒ System resource check failed: {stats_result.stderr}")
                return False
                
        except Exception as e:
            self.results['system_resources'] = {
                'status': 'FAIL',
                'error': str(e)
            }
            self.logger.error(f"âŒ System resource check failed: {str(e)}")
            return False

    def test_end_to_end_latency(self):
        """ì—”ë“œíˆ¬ì—”ë“œ ì§€ì—°ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        self.logger.info("Testing end-to-end latency (simplified)...")
        
        try:
            # ê°„ë‹¨í•œ ë©”ì‹œì§€ ë¼ìš´ë“œíŠ¸ë¦½ í…ŒìŠ¤íŠ¸
            start_time = time.time()
            
            # ìµœì‹  ë©”ì‹œì§€ 1ê°œ ìˆ˜ì‹  (íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸ìš©)
            consumer_result = subprocess.run([
                'docker', 'exec', 'fms-kafka-1',
                'kafka-console-consumer', '--bootstrap-server', 'kafka-1:9092',
                '--topic', 'fms-raw-data', '--max-messages', '1'
            ], capture_output=True, text=True, timeout=15)
            
            end_time = time.time()
            
            if consumer_result.returncode == 0 and consumer_result.stdout.strip():
                # ë©”ì‹œì§€ íŒŒì‹±
                try:
                    message = json.loads(consumer_result.stdout.strip())
                    message_time = datetime.fromisoformat(message['time'].replace('Z', '+00:00'))
                    current_time = datetime.now(message_time.tzinfo)
                    
                    latency = (current_time - message_time).total_seconds()
                    retrieval_time = end_time - start_time
                    
                    self.results['end_to_end_latency'] = {
                        'status': 'PASS' if latency < 60 else 'WARN',  # 60ì´ˆ ì´ë‚´
                        'message_to_consumption_latency_sec': round(latency, 2),
                        'retrieval_time_sec': round(retrieval_time, 2),
                        'message_timestamp': message['time'],
                        'device_id': message['DeviceId']
                    }
                    
                    self.logger.info(f"âœ… End-to-end latency:")
                    self.logger.info(f"   - Message latency: {latency:.2f} seconds")
                    self.logger.info(f"   - Retrieval time: {retrieval_time:.2f} seconds")
                    
                    return True
                    
                except json.JSONDecodeError:
                    self.logger.warning("Could not parse message for latency test")
                    
            self.results['end_to_end_latency'] = {
                'status': 'WARN',
                'message': 'Could not retrieve message for latency test'
            }
            self.logger.warning("âš ï¸ End-to-end latency test inconclusive")
            return True
            
        except Exception as e:
            self.results['end_to_end_latency'] = {
                'status': 'FAIL',
                'error': str(e)
            }
            self.logger.error(f"âŒ End-to-end latency test failed: {str(e)}")
            return False

    def run_all_tests(self):
        """ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Starting FMS Performance Benchmark")
        self.logger.info("=" * 60)
        
        start_time = time.time()
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        tests = [
            ("Kafka Cluster Health", self.test_kafka_cluster_health),
            ("Data Collector Performance", self.test_data_collector_performance),
            ("Spark Cluster Health", self.test_spark_cluster_health),
            ("System Resources", self.test_system_resources),
            ("End-to-End Latency", self.test_end_to_end_latency)
        ]
        
        passed_tests = 0
        for test_name, test_func in tests:
            self.logger.info(f"\nâ–¶ï¸ Running: {test_name}")
            success = test_func()
            if success:
                passed_tests += 1
            time.sleep(2)  # í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ìš”ì•½
        self.print_benchmark_summary(len(tests), passed_tests, total_time)
        
        return passed_tests == len(tests)

    def print_benchmark_summary(self, total_tests, passed_tests, total_time):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š PERFORMANCE BENCHMARK SUMMARY")
        self.logger.info("=" * 60)
        
        failed_tests = total_tests - passed_tests
        success_rate = (passed_tests / total_tests) * 100
        
        self.logger.info(f"Total Tests: {total_tests}")
        self.logger.info(f"âœ… Passed: {passed_tests}")
        self.logger.info(f"âŒ Failed: {failed_tests}")
        self.logger.info(f"ğŸ“ˆ Success Rate: {success_rate:.1f}%")
        self.logger.info(f"â±ï¸ Total Time: {total_time:.2f} seconds")
        
        # ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ
        self.logger.info("\nğŸ¯ Key Performance Metrics:")
        
        if 'data_collector_performance' in self.results:
            perf = self.results['data_collector_performance']
            if 'throughput_msg_per_sec' in perf:
                self.logger.info(f"   ğŸ“Š Data Throughput: {perf['throughput_msg_per_sec']} msg/sec")
        
        if 'end_to_end_latency' in self.results:
            latency = self.results['end_to_end_latency']
            if 'message_to_consumption_latency_sec' in latency:
                self.logger.info(f"   â° E2E Latency: {latency['message_to_consumption_latency_sec']} seconds")
        
        if 'spark_health' in self.results:
            spark = self.results['spark_health']
            if 'workers_alive' in spark:
                self.logger.info(f"   ğŸ”§ Spark Workers: {spark['workers_alive']} alive")
        
        # ì„¸ë¶€ ê²°ê³¼
        self.logger.info("\nğŸ“‹ Detailed Results:")
        for test_name, result in self.results.items():
            status_icon = "âœ…" if result['status'] == 'PASS' else "âš ï¸" if result['status'] == 'WARN' else "âŒ"
            self.logger.info(f"{status_icon} {test_name.replace('_', ' ').title()}: {result['status']}")
        
        if failed_tests == 0:
            self.logger.info("\nğŸ‰ All performance tests completed successfully!")
        else:
            self.logger.info(f"\nâš ï¸ {failed_tests} test(s) had issues. System is partially operational.")

if __name__ == "__main__":
    benchmark = FMSPerformanceBenchmark()
    success = benchmark.run_all_tests()
    
    exit(0 if success else 1)
